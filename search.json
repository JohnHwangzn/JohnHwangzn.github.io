[{"title":"Pytorch 分布式数据并行训练 Distributed data parallel training","url":"/2023/03/22/Pytorch-分布式数据并行训练-Distributed-data-parallel-training/","content":"\n\n\n翻译自: [Distributed data parallel training in Pytorch](https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html)\n\n\n\n# 动机\n\n加速神经网络最容易的方式就是使用单个 GPU, 在一些类型的计算中, 比如在神经网络中常见的矩阵乘法和矩阵加法, 与 CPU 相比, GPU 可以提供巨大的速度提升. 因为模型以及数据集变得越来越大, 单个 GPU 很快变得不够用了. 例如, 像 [BERT](https://arxiv.org/abs/1810.04805) 和 [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) 这样的大语言模型是在数百张 GPUs 上训练的. 为了进行多张 GPU 训练, 我们必须有一种方式在不同的 GPU 之间分割模型和数据, 并协调训练.\n\n# 为什么需要分布式的数据并行\n\nPytorch 有两种方式在多个 GPU 之间分割模型和数据: `nn.DataParallerl` 和 `nn.DistributedDataParallel`. `nn.DataParallel` 比较简单易用, 只需要包装一下模型并运行你的训练脚本就可以了. 然而, 由于`nn.DataParallel` 使用单个进程来计算模型的权重, 然后在每一个批次中将这些权重分发到每个 GPU, 因此网络(network) 很快就成为了一个计算瓶颈, GPU 的利用率往往非常低.  此外, `nn.DataParallel` 要求所有的 GPU 都在同一个节点当中, 并且不能与 [Apex](https://nvidia.github.io/apex/amp.html) 协作用于[混合精度训练](https://devblogs.nvidia.com/mixed-precision-training-deep-neural-networks/)(mixed-precision training).\n\n# 已有的文档是不完善的\n\n通常来说, Pytorch 文档是全面且清晰的, 特别是在版本 1.0.x. 然而, 在如何使用 `DistributedDataParallel` 方面的所有的例子和教程却都是无法使用的, 不完整的, 或者有很多不相关的功能。\n\nPytorch 提供了一个关于使用 AWS 进行分布式训练的教程, 这很好地告诉你如何在 AWS 端进行各种设置. 不过, 剩下的部分就有点乱(messy), 因为它花了很长时间去展示如何计算一些指标, 然后再回到来展示如何包装你的模型, 并且启动多个进程. 它也没有描述 `nn.DistributedParallel` 是做什么的, 这使得一些相关的代码块难以理解.\n\n[这篇关于用 Pytorch 写分布式应用的教程](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)有太多的细节对于第一次了解的人来说是不必要的, 并且它对于一些没有强大的 Python 多进程背景的人来说是难以理解的. 这篇教程花了大量的时间在复制 `nn.DistributedDataParallel` 的功能. 然而, 它却没有高屋建瓴地介绍它的作用, 同时也没有提供关于如何使用它的见解.\n\n还有[一篇Pytorch 教程](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)是关于入门分布式数据并行的. 它告诉了如何进行一些配置, 但却没有介绍这些配置的作用, 然后展示了一些用于在多个 GPU 上分割模型的代码以及做了一个优化的步骤. 不幸的是, 我非常确定这里所写的代码并不能运行 (这里的函数名不匹配). 此外, 它没有告诉你如何运行这代码. 想先前的教程一样, 它也没有对分布式训练的工作方式做一个高层次的概述。\n\nPytorch 提供的最接近 MWE 的例子是 [Imagenet](https://github.com/pytorch/examples/tree/master/imagenet) 训练的例子. 不幸的是, 这个例子也展示了 Pytorch 的几乎所有的其它功能, 所以很难挑出与分布式多 GPU 相关的内容.\n\nApex 提供了他们自己的[关于 Pytorch Imagenet 例子的版本](https://github.com/NVIDIA/apex/tree/master/examples/imagenet). 这篇文档告诉你他们关于 `nn.DistributedDataParallel` 的版本是 Pytorch 版本的直接替代, 这只有在学习完如何使用 Pytorch 的版本才有所帮助.\n\n而这篇[教程](http://www.telesens.co/2019/04/04/distributed-data-parallel-training-using-pytorch-on-aws/)非常棒地说明了”在引擎盖下发生了什么”以及”`nn.DistributedDataParallel` 和 `nn.DataParallel`有什么不同” . 然而, 它却没有给出如何使用 `nn.DataParallel` 的代码例子.\n\n# 大纲\n\n本篇教程针对那些已经熟悉用 Pytorch 来训练神经网络的人, 我不会去介绍所有那些部分的代码. 我将从总结一张大图开始. 然后我会展示一个关于在 MNIST 数据集上利用 GPU 进行训练的例子. 接着, 我修改这个例子用于在多个 GPU 上进行训练, 有可能在多个节点进行, 同时一行行地解释代码的变化. 重要的是, 我也会介绍如何运行代码. 作为奖励(As a bonus), 我也会说明如何使用 Apex 去进行简单的混合精度的分布式训练\n\n# 大图概览\n\n`DistributedDataParallel` 的多进程复制模型到多个 GPU 当中, 每一个 GPU 都由一个进程控制. (一个进程就是运行在计算机中的一个 Python 实例; 通过并行运行多个进程, 我们可以利用多核 CPU 处理器的优势. 你可以让一个进程控制多个 GPU , 但是这应该会比让一个进程控制一个 GPU 要慢得多. 为每个 GPU 设置多个工人(worker)进程来获取数据也是可行的, 但是为了简单起见, 我打算省略这部分内容.) 多个 GPU 可以都在一个节点中, 也可以遍布在多个节点中. (一个节点指的是一台计算机, 包含 CPU 和 GPU. 如果你正在使用 AWS, 那么一个节点就是一个 ECS 实例.) 每一个进程进行一些相同的任务, 并且每个进程都与其它所有的进程进行通信. 在多个 GPU 之间, 只有梯度会被传送, 如此网络通信就是一个较小的瓶颈了.\n\n![Untitled](Pytorch%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83Distributed%20data%20parallel%20trainin%203d11d701319846be99b9c4610ee4cbfb/Untitled.png)\n\n在训练过程中, 每个进程从硬盘中加载它们自己对应的小批量数据, 然后传送到它们对应的 GPU. 每一个 GPU 进行它们各自的前向传播过程, 然后在多个 GPU 中的梯度会被集中计算(all-reduced). 由于每一个层的梯度不依赖于上一个层的梯度, 因此梯度的集中计算(all-reduced)是与后向传播同时(concurrently)计算的，以进一步缓解网络瓶颈。在反向传播结束时, 每一个节点都有平均的梯度, 这确保了模型的权重保持同步.\n\n所有这些要求了(可能在多个节点之中的)多个进程是同步的并且保持通信. Pytorch 通过 `distributed.init_precoess_group` 函数来完成这件事情. 这个函数需要知道去哪找进程 0, 以便所有的进程都能同步, 同时还需要知道预期的进程总数. 每一个进程还需要知道进程的总数, 它在所有进程当中的排序(rank)以及要用哪个 GPU. 进程的总数通常称为 `world size` 世界尺度. 最后, 每一个进程需要知道要工作在哪一个数据, 以便批量数据之间不会重叠. Pytorch 提供了 `nn.utils.data.DistributedSampler` 来完成这件事.\n\n# 最小工作例子与解释\n\n为了说明如何完成这件事, 我将创建一个在 MNIST 数据集上训练的例子, 然后对其进行修改，以便在多个节点的多个GPU上运行，最后还允许混合精度的训练。\n\n## 非多进程\n\n首先, 导入我们所需要的包.\n\n```python\nimport os\nfrom datatime import datetime\nimport argparse\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transformers as transformers\nimport torch\nimport torch.nn as nn\nimport torch.distributed as dist\nfrom apex.parallel import DistributedDataParallel as DDP\nfrom apex import amp\n```\n\n我们定义一个非常简单的卷积模型用于预测 MNIST.\n\n```python\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.fc = nn.Linear(7 * 7 * 32, num_classes)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n```\n\n`main()` 函数接收一些参数, 然后运行训练函数.\n\n```python\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-n', '--nodes', default=1, type=int, metavar='N')\n    parser.add_argument('-g', '--gpus', default=1, type=int, help='number of gpus per node')  # Adding a 'gpus' argument\n    parser.add_argument('-nr', '--nr', default=0, type=int, help=\"ranking within the nodes\")\n    parser.add_argument('--epochs', default=2, type=int, metavar='N', help='number of total epochs to run')\n    args = parse.parse_args()\n    train(0, args)\n```\n\n`train()` 函数\n\n```python\ndef train(gpu, args):\n    torch.manual_seed(0) # By setting the seed, any random numbers generated by PyTorch after this line will be deterministic and reproducible, given the same seed value. \n    model = ConvNet()\n    torch.cuda.set_device(gpu) # sets the current GPU device to the specified index\n    model.cuda(gpu)\n    batch_size = 100\n\n    # define loss function\n    criterion = nn.CrossEntropyLoss().cuda(gpu)\n    # define optimizer\n    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n    # Data Loading Code\n    train_dataset = torchvision.datasets.MNIST(root='./data',\n                                               train=True,\n                                               trainsform=transformers.ToTensor(),\n                                               download=True)\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                               batch_size=batch_size, \n                                               shuffle=True, \n                                               num_workers=0, \n                                               pin_memory=True)\n    start = datetime.now()\n    total_step = len(train_loader)\n    for epoch in range(args.epochs):\n        for i, (images, labels) in enumerate(train_loader):\n            images = images.cuda(non_blocking=True)\n            labels = labels.cuda(non_blocking=True)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if (i + 1) % 100 == 0 and gpu == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n                    epoch + 1, \n                    args.epochs, \n                    i + 1, \n                    total_step,\n                    loss.item())\n                   )\n    if gpu == 0:\n        print(\"Training complete in: \" + str(datetime.now() - start))\n```\n\n最后, 我们确保 `main()` 函数被调用.\n\n```python\nif __name__ == '__main__':\n    main()\n```\n\n这里有一些暂时还不需要的额外的东西, 但将这整个骨架放在这里是有好处的.\n\n我们可以通过在打开一个终端并执行 `python src/mnist.py -n 1 -g 1 -nr 0` 来运行这段代码.\n\n## 多进程\n\n为了用多进程来完成这件事, 我们需要一个为每一个 GPU 启动一个进程的脚本. 每一个进程需要知道要用哪一个 GPU, 以及它在所有运行中的进程中的排序. 我们需要在每一个节点都运行这个脚本.\n\n让我们看一下每一个函数的变化. 我已经将新代码用栅栏包围起来, 以便容易查找.\n\n```python\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-n', '--nodes', default=1, type=int, metavar='N') # 我们计划使用的节点总数\n    parser.add_argument('-g', '--gpus', default=1, type=int, help='number of gpus per node')  # 一个节点中的 GPU 总数\n    parser.add_argument('-nr', '--nr', default=0, type=int, help=\"ranking within the nodes\")  # 当前节点在所有节点中的排序, 从 0 到 args.nodes - 1\n    parser.add_argument('--epochs', default=2, type=int, metavar='N', help='number of total epochs to run') # 扫描数据的轮数\n    args = parse.parse_args()\n    \n    ############################################################\n    args = parser.parse_args()                                 #\n    args.world_size = args.gpus * args.nodes # GPU 总数         #\n    os.environ['MASTER_ADDR'] = '10.57.23.164'                 #\n    os.environ['MASTER_PORT'] = '8888'                         # \n    **mp.spawn(train, nprocs=args.gpus, args=(args, ))**           #   \n    ############################################################\n```\n\n- `args.nodes`: 我们计划使用的节点总数\n- `args.gpus`: 一个节点中的 GPU 总数\n- `args.nr`: 当前节点在所有节点中的排序, 从 0 到 args.nodes - 1\n\n**代码详解**\n\n`args.world_size = args.gpus * args.nodes`\n\n基于节点总数和一个节点中包含的 GPU 数, 我们可以计算 `word_size`, 或者说是将要运行的进程的总数, 这等同于 GPU 的总数, 因为我们为每一个 GPU 分配一个 进程.\n\n`os.environ['MASTER_ADDR'] **=** '10.57.23.164'`\n\n`os.environ['MASTER_PORT'] **=** '8888'`\n\n这两行代码告诉多进程模块寻找进程 0 时的 IP 地址和端口号. 它需要这个地址, 以便所有的进程在初期都能同步.\n\n`mp.spawn(train, nprocs**=**args.gpus, args**=**(args,))`\n\n现在，我们不再是只运行一次 `train` 函数，而是会生成 `args.gpus` 个进程，每个进程都会运行 `train(i, args)` 函数，其中 `i` 为进程的编号, 同时也对应 GPU 的编号, 其取值范围为 `0` 到 `args.gpus - 1`。请记住, 我们在每一个节点运行 `main()` 函数, 以便在总体上有 `args.nodes * args.gpus = args.world_size`  个进程. 关于 `train(i, args)` 函数中参数 `i` 是如何传入的, 请看 文末的 WIKI.\n\n我们可以在终端中运行 `export MASTER_ADDR=10.57.23.164` 和 `export MASTER_PORT=8888`，而不使用 `os.environ['MASTER_ADDR'] **=** '10.57.23.164'` 和 `os.environ['MASTER_PORT'] **=** '8888'` 这两行代码。\n\n接下来, 让我们看一下 `train` 函数的变化. 我将同样用栅栏包围新的代码.\n\n```python\ndef train(gpu, args):\n    ############################################################\n    rank = args.nr * args.gpus + gpu                              \n    dist.init_process_group(                                   \n        backend='nccl',                                         \n           init_method='env://',                                   \n        world_size=args.world_size,                              \n        rank=rank                                               \n    )                                                          \n    ############################################################\n    \n    torch.manual_seed(0)\n    model = ConvNet()\n    torch.cuda.set_device(gpu)\n    model.cuda(gpu)\n    batch_size = 100\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(gpu)\n    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n    \n    ###############################################################\n    # Wrap the model\n    model = nn.parallel.DistributedDataParallel(model,\n                                                device_ids=[gpu])\n    ###############################################################\n\n    # Data loading code\n    train_dataset = torchvision.datasets.MNIST(\n        root='./data',\n        train=True,\n        transform=transforms.ToTensor(),\n        download=True\n    )                                               \n    ################################################################\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=args.world_size,\n        rank=rank\n    )\n    ################################################################\n\n    train_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n       batch_size=batch_size,\n    ##############################\n       shuffle=False,            #\n    ##############################\n       num_workers=0,\n       pin_memory=True,\n    #############################\n      sampler=train_sampler)    # \n    #############################\n    ...\n```\n\n为了简洁起见，我已经从这个例子中删除了训练循环，并用 `...` 替换了它，但是在[完整的脚本](https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-distributed.py)中仍然存在。\n\n**代码详解**\n\n`rank **=** args.nr ***** args.gpus **+** gpu`\n\n这是当前进程在所有进程当中的全局排序(一个进程对应一个GPU). \n\n`dist.init_process_group(                                   \n    backend='nccl',                                         \n    init_method='env://',                                   \n    world_size=args.world_size,                             \n    rank=rank                                               \n)`  \n\n初始化进程并与其它进程连接. 这是”阻塞态”, 意味着直到所有进程都加入以后进程才会继续工作. 我们在这里使用了 `ncll` 后端, 因为 [Pytorch Docs](https://pytorch.org/docs/stable/distributed.html) 说了它是可用的最快的一个. `init_method` 告诉进程组去哪寻找一些设置. 在这个例子当中, 它在环境变量当中寻找 `MASTER_ADDR` and `MASTER_PORT` , 这两个变量我们在 `main` 函数里设置了. 我本可以在那里设置 word_size, 但是我选择了将它设置为关键词参数, 与当前进程的全局排名一起在此处设置.\n\n`model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu])`\n\n将模型包装成 `DistributedDataParallel` 模型. 这把模型复制到GPU上进行处理。\n\n`train_sampler = torch.utils.data.distributed.DistributedSampler(\n    train_dataset,\n    num_replicas=args.world_size,\n    rank=rank\n)`\n\n`torch.utils.data.distributed.DistributedSampler` 确保了每个进程获取的是训练数据中不同的部分.\n\n`train_loader = torch.utils.data.DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=False,        \n    num_workers=0,\n    pin_memory=True,\n    sampler=train_sampler)`\n\n`shuffle=False` 请使用 `nn.utils.data.DistributedSampler` 而不是通常的随机打乱的方式。\n\n要在 4 个节点上, 其中每个节点有 8 个GPU, 运行此程序，我们需要 4 个终端（每个节点一个）。在节点 0:\n\n```bash\n$ python src/mnist-distributed.py -n 4 -g 8 -nr 0\n```\n\n然后, 在其它节点:\n\n```bash\n$ python src/mnist-distributed.py -n 4 -g 8 -nr i\n```\n\n其中, $i \\in 1, 2, 3$/ 换句话说, 我们在每个节点都运行这个脚本, 告诉它在训练开始之前启动与彼此同步的 `args.gpus` 个进程。\n\n请注意，现在的有效批处理大小是每个 GPU 的批处理大小（脚本中的值）* GPU总数（worldsize）。\n\n# 使用 Apex 进行混合精度训练\n\n混合精度训练, float(FP32) 和 half(FP16) 精度的结合的训练, 允许我们使用更大的批量大小以及利用 [NVIDIA Tensor Cores](https://www.nvidia.com/en-us/data-center/tensorcore/) 的优势进行快速计算.  AWS [p3](https://aws.amazon.com/ec2/instance-types/p3/) 实例使用 NVIDIA Tesla V100 GPUs with Tensor Cores. 我们只需要改变 `train` 函数. 为了简洁起见, 我从上面的例子当中拿掉了数据加载的代码以及反向传播以后的代码, 并且用 `...` 进行了代替, 但是它们仍可以在[完整脚本](https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-mixed.py)中获取.\n\n```python\nrank = args.nr * args.gpus + gpu\ndist.init_process_group(\n    backend='nccl',\n    init_method='env://',\n    world_size=args.world_size,\n    rank=rank)\n        \ntorch.manual_seed(0)\nmodel = ConvNet()\ntorch.cuda.set_device(gpu)\n**model.cuda(gpu)**\nbatch_size = 100\n# define loss function (criterion) and optimizer\ncriterion = nn.CrossEntropyLoss().cuda(gpu)\noptimizer = torch.optim.SGD(model.parameters(), 1e-4)\n# Wrap the model\n##############################################################\n**model, optimizer = amp.initialize(model, optimizer, \n                                  opt_level='O2')**\nmodel = DDP(model)\n##############################################################\n# Data loading code\n...\nstart = datetime.now()\ntotal_step = len(train_loader)\nfor epoch in range(args.epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.cuda(non_blocking=True)\n        labels = labels.cuda(non_blocking=True)\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n##############################################################\n        **with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()**\n##############################################################\n        optimizer.step()\n ...\n```\n\n**代码详解**\n\n`model, optimizer = amp.initialize(model, optimizer, opt_level='O2')`\n\n`amp.initialize` 包装模型和优化器以便用于混合精度训练. 注意, 在调用 `amp.initialize` 之前模型必须要在正确的 GPU 上. `opt_level`从`O0`开始，使用所有浮点数，到 `O3`为止，始终使用半精度。 `O1`和`O2`是不同程度的混合精度，在[Apex文档](https://nvidia.github.io/apex/amp.html#opt-levels-and-properties)中可以找到详细信息。是的，所有这些代码中的第一个字符都是大写字母“O”，而第二个字符是数字。如果您使用零代替它，将会收到令人困惑的错误消息。\n\n`model = DDP(model)`\n\n`apex.parallel.DistributedDataParallel` 是 `nn.DistributedDataParallel` 的即插即用替代品。我们**不再需要指定 GPU**，因为 Apex 每个进程只允许一个 GPU。它还假设脚本在将模型移动到 GPU 之前调用`torch.cuda.set_device(local_rank)`。\n\n`with amp.scale_loss(loss, optimizer) as scaled_loss:\n    scaled_loss.backward()`\n\n混合精度训练需要对损失进行缩放，以防止梯度下溢。Apex 会自动完成此操作。\n\n这个脚本的运行方式与分布式训练脚本相同。\n\n# 感谢\n\nMany thanks to the computational team at VL56 for all your work on various parts of this. I’d like to especially thank Stephen Kottman, who got a MWE up while I was still trying to figure out how multiprocessing in Python works, and then explained it to me, and Andy Beam, who greatly improved the first draft of this tutorial.\n\n非常感谢 VL56 的计算团队，感谢你们在各个部分的工作。我想特别感谢 Stephen Kottman，他在我还在试图弄清楚 Python 中的多处理是如何工作的时候，就弄出了一个 MWE，然后向我解释，还有 Andy Beam，他大大改进了本教程的初稿。\n\n# 完整的脚本\n\n```python\nimport os\nfrom datetime import datetime\nimport argparse\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nimport torch.distributed as dist\nfrom apex.parallel import DistributedDataParallel as DDP\nfrom apex import amp\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-n', '--nodes', default=1, type=int, metavar='N',\n                        help='number of data loading workers (default: 4)')\n    parser.add_argument('-g', '--gpus', default=1, type=int,\n                        help='**number of gpus per node**')\n    parser.add_argument('-nr', '--nr', default=0, type=int,\n                        help='**ranking within the nodes**')\n    parser.add_argument('--epochs', default=2, type=int, metavar='N',\n                        help='number of total epochs to run')\n    args = parser.parse_args()\n    args.world_size = args.gpus * args.nodes\n    os.environ['MASTER_ADDR'] = '10.57.23.164'\n    os.environ['MASTER_PORT'] = '8888'\n    mp.spawn(train, nprocs=args.gpus, args=(args,))\n\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.fc = nn.Linear(7*7*32, num_classes)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\ndef train(gpu, args):\n    rank = args.nr * args.gpus + gpu\n    dist.init_process_group(backend='nccl', init_method='env://', world_size=args.world_size, rank=rank)\n    torch.manual_seed(0)\n    model = ConvNet()\n    torch.cuda.set_device(gpu)\n    model.cuda(gpu)\n    batch_size = 100\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(gpu)\n    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n    # Wrap the model\n    model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n    # Data loading code\n    train_dataset = torchvision.datasets.MNIST(root='./data',\n                                               train=True,\n                                               transform=transforms.ToTensor(),\n                                               download=True)\n    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n                                                                    num_replicas=args.world_size,\n                                                                    rank=rank)\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                               batch_size=batch_size,\n                                               shuffle=False,\n                                               num_workers=0,\n                                               pin_memory=True,\n                                               sampler=train_sampler)\n\n    start = datetime.now()\n    total_step = len(train_loader)\n    for epoch in range(args.epochs):\n        for i, (images, labels) in enumerate(train_loader):\n            images = images.cuda(non_blocking=True)\n            labels = labels.cuda(non_blocking=True)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if (i + 1) % 100 == 0 and gpu == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, args.epochs, i + 1, total_step,\n                                                                         loss.item()))\n    if gpu == 0:\n        print(\"Training complete in: \" + str(datetime.now() - start))\n\nif __name__ == '__main__':\n    main()\n```\n\n# WIKI\n\n**Q1**\n\n`def train(gpu, args)` \n\n`mp.spawn(train, nprocs=args.gpus, args=(args,))`\n\n`train` 函数的 `gpu` 参数是怎么被传入进去的, 并且怎么会和进程号一一对应呢?\n\n在这个代码中，`train` 函数的 `gpu` 参数是在 `mp.spawn(fn=train, nprocs=args.gpus, args=(args,))` 这一行代码中被传入的。内部使用了 Python 的 multiprocessing 模块来实现多进程训练. `mp.spawn`中 `fn` 参数指定了多进程的入口函数, 该函数以`fn(i, *args)`的形式调用，其中`i`是进程索引，`args`是由一个参数元组传入, 即参数 `args=(args, )`. 同时, `nprocs` 参数指定了进程数.\n\n让我们来看源代码:\n\n```python\ndef spawn(fn, **args=()**, nprocs=1, join=True, daemon=False, start_method='spawn'):\n    if start_method != 'spawn':\n        msg = ('This method only supports start_method=spawn (got: %s).\\n'\n               'To use a different start_method use:\\n        '\n               ' torch.multiprocessing.start_process(...)' % start_method)\n        warnings.warn(msg)\n  return start_processes(fn, **args**, nprocs, join, daemon, start_method='spawn')\n\ndef start_processes(fn, **args=()**, nprocs=1, join=True, daemon=False, start_method='spawn'):\n    mp = multiprocessing.get_context(start_method)\n    error_queues = []\n    processes = []\n    for i in range(nprocs):\n        error_queue = mp.SimpleQueue()\n        process = mp.Process(\n            target=_wrap,\n            **args=(fn, i, args, error_queue),**\n            daemon=daemon,\n        )\n        process.start()\n        error_queues.append(error_queue)\n        processes.append(process)\n\n    context = ProcessContext(processes, error_queues)\n    if not join:\n        return context\n\n    # Loop on join until it returns True or raises an exception.\n    while not context.join():\n        pass\n```\n\n```python\nfor **i** in range(nprocs):\n    error_queue = mp.SimpleQueue()\n    process = mp.Process(\n        target=_wrap,\n        **args=(fn, i, args, error_queue),**\n        daemon=daemon,\n    )\n        ...\n```\n\n根据这个代码片, 我们可以发现, `spawn()` 函数中传入的参数 args, 会最终成为 `mp.Process()` 类的构造参数 `args` 中一个元素, 该构造参数 `args` 中还包括 `i`, 这指的是进程的索引. 因此, 我们就可以很清楚的知道 `train(gpu, args)` 中的参数 `gpu` 是如何被传入的并与进程索引一一对应了.","tags":["Pytorch","多 GPU 训练"]},{"title":"读书上大学，到底能回报我们多少钱？","url":"/2023/01/29/读书上大学，到底能回报我们多少钱？/","content":"\n\n\n> 世界有很多残酷的事实，我们希望把它们摆在你面前，帮你看清各种选择的利弊，总比永远在不自知中颓废落后强。\n\n\n\n\n结论：\n- 在人们接受完所有教育以后获得的经济回报、职业地位中，只有 `$1/3$` 真正来自校内校外的教育，而 `$2/3$` 是由家庭背景和先天能力带来的。在剔除掉学生的先天能力、家庭背景因素以后，中国大学教育的平均回报率是 `$10\\%$`，而高中教育回报率为 $0$ 。\n- 拼能力、拼学历、拼家庭，你总得有一样能拿到手。也许家庭是一个人无法改变的宿命，但是能力可以加强，学历可以提升。\n\n\n\n# 一、大学回报率\n\n\n\n教育回报(*return on investment of education*)，可以分为显性收入和隐性收入，显性收入主要指经济收入，隐性收入包括知识水平、认知能力、社会地位晋升、人脉资源增加、婚姻回报等。\n\n大学回报率，指的是多一年教育，收入就增长多少百分比。\n\n大学回报率的影响因素：\n1. **个人能力**。**“情绪稳定、性格外向、乐于尝试、为人亲和、做事尽责”** 这五项能力决定了一个人能否在事业上取得成功，其中“情绪稳定、性格外向和做事尽责”最为重要。学历和能力并不相同，要想取得成功，两者中至少要占一样。\n2. **学校质量**。名牌大学不仅教学质量高、社会声誉高，而且校友资源广，也会在精神境界、人脉广度、社会软资源等方面上，给予学生更多的支持。\n3. **所选专业**。总的来说，工程类、计算机类和数学专业，会比文科类专业的回报率更高。\n4. **家庭背景**。出身于富裕家庭的孩子，即使能力不佳，也会因为家庭背景优越，而不至于掉下已有阶层。其中原因在于，家境优越的中产父母，为了防止自己孩子阶层下滑，利用金钱优势、社会资源、人脉关系，为孩子有效创造了一个“玻璃屏障”。所谓“玻璃屏障”，就是由足够金钱、知识和资源拓展开来的丰富的学习机会，让经济优越的孩子学到足够的**社交能力、情绪控制能力，以及自律、沟通、坚持、坚毅**等非认知能力。\n\n\n\n# 二、家庭背景的力量难以撼动\n\n\n\n1. 刚毕业时的收入。家庭收入水平越高，父母学历越高，孩子在大学刚毕业时收入就越高。\n2. 整个职业生涯的收入。哪怕毕业十年，也依然有近 $1/3$ 来自底层阶级的大学生，仍旧摆脱不了底层的命运，无法获得社会阶层的流动。\n3. 事业晋升空间。家庭收入在全国 $25\\%$ 的大学毕业生，有 $18\\%$ 的人成为了**高级管理者**，家庭收入在 $25\\%$ 的大学生，则有 $33\\%$ 止步于**中底层管理者**，成为高级管理者的人更少。富裕家庭的父母，会不遗余力地在家庭资源、社会关系方面，对孩子的事业给予支持。\n\n\n\n# 三、为什么一张大学文凭，依旧敌不过家庭出身\n\n\n\n造成收入差距的原因：\n1. **童年时期的家庭资源**。家庭背景可以通过**经济资本、文化资本和社会资本**三种途径对下一代产生影响，如在教育中花更多的时间、精力和金钱（经济资本）；获得足够的能力、气质和毅力等职场能力，持有更高的理想抱负（文化资本）；通过广泛的社会关系帮助孩子更好地实现求职和晋升（社会资本）。\n2. **贫困学生所读地大学质量**。顶尖大学中绝大多数学生，都来自中产或以上阶层，在中国如此，在美国更是如此。其中原因，有贫困家庭学生的认知能力、非认知能力较落后。越是精英大学，越是集中了家庭背景好的学生。多数贫困家庭的学生只能去普通大学、专科学校，这也就造成他们很难在毕业后找到收入丰厚的工作。\n3. **贫穷带来的稀缺感、束缚了努力的脚步**。贫穷会成为心智的负担，即使没有人提醒你稀缺的存在，贫穷状态也会削弱智力和自控力。比如，挨过饿的人，会长期过于关注食物，买菜做饭时也很容易准备过量，或饱受暴食症的困扰；小时候被严格限制零用钱的孩子，等自己有能力挣钱以后，依然会由于内心挥之不去的匮乏感，**要么不敢花钱、永远感觉缺钱，要么挥霍无度，缺乏必要的理财理念**。家庭富足的人可以专注于自身能力发展。\n\n\n\n# 四、回报率低，就不读大学了吗\n\n\n\n1. 不需要科技含量的小五金创业时代即将成为过去，“没有读书”的人要想再创业成功，已近痴人说梦。低技术行业已经形成垄断。企业通过高科技来提升行业壁垒。\n2. 拼能力、拼学历、拼家庭，你总得有一样能拿到手。也许家庭是一个人无法改变的宿命，但是能力可以加强，学历可以提升。\n3. 一代人的微小努力，都会在下一代身上产生不小的收益。\n","tags":["读书笔记"]},{"title":"搭建 Hexo 博客并部署到 GitHub Pages 流程","url":"/2022/07/27/搭建-Hexo-博客并部署到-Github-Pages-流程/","content":"\n\n# 搭建 Hexo 博客并部署到 GitHub Pages 流程\n\n# 0. 前言\n\n[Hexo](https://hexo.bootcss.com/) 是一个静态博客（纯 HTML 格式）框架，使用 Markdown 解析文章，支持一键部署到 [GitHub Pages](https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages)、Heroku 等静态网站托管平台上。Hexo 是目前最主流的静态博客框架之一，同类型的框架还有 [Hugo](https://gohugo.io/)、[jekyll](https://jekyllrb.com/)。关于这三款框架的对比，可以参见 [Jekyll / Hugo / Hexo Comparison | The Coding Notes (lexcao.io)](https://lexcao.io/posts/jekyll-hugo-hexo/)。\n\n# 1. 搭建步骤\n\nHexo 依赖以下两个应用程序：\n\n- Git\n- Node.js\n\n## 1.1 安装 Git\n\nGit 是一个版本控制系统，可以跟踪文件修改历史，通常用于程序的协同开发。\n\n- Windows：下载并安装 [Git - Downloading Package (git-scm.com)](https://git-scm.com/download/win)-\n- 镜像下载地址：[淘宝 Git for Windows 镜像](https://npm.taobao.org/mirrors/git-for-windows/)\n\n验证安装：\n\n```powershell\n> git --version\n```\n\n如果能正常返回版本信息，则说明安装成功。\n\n## 1.2 安装 Node.js\n\nNode.js 是一个 JavaScript 运行时环境（***runtime environment***），主要用于在服务器端执行 JavaScript 代码。\n\nNPM（“Node Package Manager”）是 JavaScript 运行时 Node.js 的默认程序包管理器，主要用于发布，托管和下载 JavaScript 程序包。\n\n- Windows：下载并安装 [Download | Node.js (nodejs.org)](https://nodejs.org/en/download/)\n- 镜像下载地址：[淘宝 Node.js 镜像](https://npm.taobao.org/mirrors/node)\n  \n    \n\n验证安装：\n\n```powershell\n> node -v\n> npm -v\n```\n\n如果能正常返回版本信息，则说明安装成功。\n\n## 1.3 安装 Hexo\n\n安装完 Node.js 以后，即可使用 npm 来安装 hexo:\n\n```powershell\n> npm install -g hexo-cli\n```\n\n\n如果由于网络问题导致 npm 安装过程比较缓慢，则可以考虑更换软件源。\n\n```powershell\n# 查看现有源\n> npm config get registry\n\n# 设置淘宝源\n> npm config set registry https://registry.npm.taobao.org\n\n# 更新包\n> npm update\n```\n\n更换源以后，再次执行上面的安装命令即可。\n\n## 1.4 快速建站\n\nhexo 安装完成以后，执行以下命令初始化一个 hexo 工程：\n\n```powershell\n> hexo init <folder>\n> cd <folder>\n> npm install\n```\n\n初始化完成后，生成新的目录 `<folder>`，其目录结果如下：\n\n```powershell\n.\n├── _config.yml   # 网站的配置信息\n├── package.json  # 应用程序的信息\n├── scaffolds     # 模版文件夹（模板指的是在新建的文章文件中默认添加的内容）：当新建文章时，Hexo 会根据 scaffold 来构建文件。\n├── source        # 用户资源\n|   ├── _drafts      # 草稿\n|   └── _posts       # 发布稿\n└── themes        # 主题，hexo 会根据 themes 来生成静态页面\n```\n\n接着，生成静态网页文件：\n\n```powershell\n> hexo generate\n```\n\n此时一个新的目录 `<folder>/public` 被生成，它是网站的根目录。在 source 目录下，所有 Markdown 和 HTML 文件会被解析后放到 public 文件夹，而其他文件会被直接拷贝过去。注意，除了 _posts 以外，其他带 _ 的文件/目录都会被忽略，即不会被放到 public 目录下。\n\n新的目录结构如下：\n\n```\n.\n├── _config.yml   # 网站的配置信息\n├── package.json  # 应用程序的信息\n├── scaffolds     # 模版文件夹（模板指的是在新建的文章文件中默认添加的内容）：当新建文章时，Hexo 会根据 scaffold 来构建文件。\n|   ├── draft.md      # 草稿模版\n|   ├── page.md       # 页面模板\n|   └── post.md       # 文章模板\n├── source        # 用户资源\n|   ├── _drafts      # 草稿\n|   └── _posts       # 发布稿\n├── themes        # 主题，hexo 会根据 themes 来生成静态页面\n└── public        # 网站根目录。source 目录下，Markdown 和 HTML 文件会被解析后放到 public 文件夹，而其他文件会被直接拷贝过去。\n    ├── css         # 注意，除了 _posts 以外，其他带 _ 的文件/目录都会被忽略，即不会被放到 public 目录下。\n    ├── js\n    └── ···     \n                                    \n```\n\n最后，打开本地服务器，并用浏览器访问网页 `http://localhost:4000/`：\n\n```powershell\n> hexo s\n\nINFO  Start processing\nINFO  Hexo is running at **http://localhost:4000/** . Press Ctrl+C to stop.\n```\n\n至此，一个网站就搭建完成了！\n\n## 1.5 设置 Github Pages \n\n现在，我们将这个网站部署到 Github Pages 上。\n\n步骤如下：\n\n1. 注册 Github 账号，[注册](https://github.com/)。\n   \n2. 创建一个仓库（**Repository**），取名必须是 ```<username>.github.io``` \n   <br/>\n   \n\n![](1-GitHub_Pages.png)\n    \n3. 配置 SSH 免密登录\n   \n    由于提交代码到 GitHub 需要账号权限，因此需要登录账号。考虑到安全和方便，我们不直接使用账号和密码，而使用 ssh 的公钥密钥机制进行登录。具体操作如下：\n    \n    - 在本机执行以下命令，并复制输出的内容：\n      \n        ```powershell\n        > ssh-keygen -t rsa -C <github email>\n        > cat C:\\Users\\<username>\\.ssh\\id_rsa.pub\n        ```\n        \n    - 打开 GitHub 账户菜单中的 Setting ⇒ SSH and GPG keys ⇒ New SSH key ，然后将复制的内容粘贴到此处，点击 `Add SSH key` 即可。\n    \n4. 验证 SSH 免密登录是否配置成功\n   \n    在本机执行以下命令：\n    \n    ```powershell\n    > ssh -T git@github.com \n    \n    如果提示:\n    Are you sure you want to continue connecting (yes/no)?\n    则输入: yes\n    \n    看到以下信息，则说明配置成功。\n    Hi <your username>! You've successfully authenticated, but GitHub does not provide shell access. \n    ```\n    \n5. 配置 Git 账号信息\n   \n    ```powershell\n    > git config --global user.name \"<your username>\"\n    > git config --global user.email \"<your github email>\" \n    ```\n    \n6. 在 `<folder>` 目录下安装 hexo-deployer-git 插件\n   \n    ```powershell\n    > cd <folder> # <folder> 是你的 hexo 工程目录\n    > npm install hexo-deployer-git --save\n    ```\n    \n7. 配置部署信息。编辑 `<folder>/_config.yml` 文件，并添加以下内容：\n   \n    ```powershell\n    deploy:\n        type: git\n        repository: git@github.com:JohnHwangzn/JohnHwangzn.github.io.git\n        branch: main\n    ```\n    \n    其中 repository 的值为 GitHub 仓库地址\n    \n8. 将网站文件推送到 GitHub 仓库\n   \n    ```powershell\n    > hexo deploy\n    ```\n    \n9. 等待 2-3 分钟后，打开网址 `https://<your username>.github.io`，就可以看到网站已经部署成功了。\n   \n    \n\n# 2. Hexo 的基本操作\n\n## 2.1 Hexo 工程的目录结构\n\n\n```\n.\n├── _config.yml   # 网站的配置信息\n├── package.json  # 应用程序的信息\n├── scaffolds     # 模版文件夹（模板指的是在新建的文章文件中默认添加的内容）：当新建文章时，Hexo 会根据 scaffold 来构建文件。\n|   ├── draft.md      # 草稿模版\n|   ├── page.md       # 页面模板\n|   └── post.md       # 文章模板\n├── source        # 用户资源\n|   ├── _drafts      # 草稿\n|   └── _posts       # 发布稿\n├── themes        # 主题，hexo 会根据 themes 来生成静态页面\n└── public        # 网站根目录。source 目录下，Markdown 和 HTML 文件会被解析后放到 public 文件夹，而其他文件会被直接拷贝过去。\n    ├── css         # 注意，除了 _posts 以外，其他带 _ 的文件/目录都会被忽略，即不会被放到 public 目录下。\n    ├── js\n    └── ···      \n                                    \n```\n\n各文件/目录的功能说明如下：\n\n- `_config.yml` : 可以进行以下设置：****网站信息、网址结构、目录配置、文章属性、分类&标签、日期/时间格式、分页、扩展、处理或忽略某些目录、使用替代配置文件****等****。****\n- `package.json` : 应用程序的信息。每个 JavaScript 项目（无论是 Node.js 还是浏览器应用程序）都可以被当作 npm 软件包，并且通过  `package.json` 来描述项目和软件包信息。\n- `scaffolds`  :   [模版](https://hexo.io/zh-cn/docs/writing)目录。当您新建文章时，Hexo 会根据 scaffold 来构建文件。模板指的是在新建的文章文件中默认添加的内容。\n- `source` ：存放用户所有文件的地方。\n- `themes` ：主题目录。Hexo 会根据主题来生成静态页面。\n- `public` ：当 hexo 生成静态页面时，在 `source` 目录下的 Markdown 和 HTML 文件会被解析并放到 `public` 目录下，而其他文件会被直接拷贝过去。注意，除 `_posts`文件夹之外，开头命名为 `_` (下划线)的文件 / 目录和隐藏的文件将会被忽略。\n\n## 2.2 创建新的文章/页面\n\n创建一篇新的文章或页面：\n\n```\n> hexo new [layout] <title>\n```\n\n### 布局（layout）\n\nhexo 的三种默认的布局：`post`、`page` 和 `draft`。这三种不同类型的文件，在被创建时，会被保存到不同的路径，对应的保存路径如下：\n\n- `post`: ```source/_posts```  \n- `page`: ```source```         \n- `draft`: ```source/_drafts``` \n\n\n### 草稿（draft）\n\n如果新建了一个草稿，那么它将会被存储在 `source/_drafts` 下。草稿默认不会显示在页面中，不过可以在执行时加上`--draft` 参数来预览草稿。可以通过 `publish` 命令将草稿移动至 `source/_posts` 目录下：\n\n```\n> hexo publish [layout] <title>\n```\n\n### 模板（Scaffold）\n\n在新建文章时，Hexo 会根据 `scaffolds` 目录下与名称相对应的文件来构建文章，例如：\n\n```\n> hexo new photo \"a wonderful day\"\n```\n\n在执行这条执行时，Hexo 会在 `scaffolds` 目录下寻找 `[photo.md](http://photo.md)` ，并根据其内容来构建文章。\n\n在模板中可以使用以下变量：\n\n\n- `layout`: 布局\n- `title`: 标题`\n- `date`: 文件建立日期\n\n\n# 3. 配置 Hexo 主题\n\nHexo 有一个主题社区：[Themes | Hexo](https://hexo.io/themes/)，在上面可以下载许多不同风格的主题。下面就以 AirCloud 主题为例，说明如何配置 Hexo 主题。\n\nAirCloud 主题预览：[http://niexiaotao.cn/](http://niexiaotao.cn/)\n\nAirCloud 下载地址：[https://github.com/aircloud/hexo-theme-aircloud](https://github.com/aircloud/hexo-theme-aircloud) \n\n## 3.1 下载主题\n\n在 `<folder>/themes` 目录下，下载 AirCloud 主题：\n\n```powershell\n> cd <folder>/themes\n> git clone https://github.com/aircloud/hexo-theme-aircloud.git\n> cd hexo-theme-aircloud\n```\n\n主题目录结构如下：\n\n```powershell\n.\n├── _config.yml  # 主题配置文件。在此处修改配置时，服务器会自动更新，而无需重启\n├── languages    # 语言文件夹\n├── layout       # 布局。用于存放主题的模板文件，决定了网站内容的呈现方式，\n├── scripts      # 脚本文件夹。在启动时，Hexo 会载入此文件夹内的 JavaScript 文件。\n└── source       # 资源文件夹，功能与 hexo 工程下的 source 目录相同。\n```\n\n## 3.2 配置主题\n\n![](2-Hexo主题.png)\n\n**启动 hexo-theme-aircloud 主题**\n\n设置 `<folder>/_config.yml` 的 `theme` 参数为 ```hexo-theme-aircloud```，就可以启动该主题。\n\n```powershell\ntheme: hexo-theme-aircloud-master\n```\n\n**启动主题中的全局搜索功能**\n\n为了使用搜索功能，首先需要安装以下插件：\n\n```powershell\n> npm i hexo-generator-search --save\n```\n\n然后在 `<folder>/_config.yml` 中进行如下配置：\n\n```powershell\nsearch:\n    path: search.json\n    field: post\n```\n\n**`标签`与`关于`页面**\n\n新项目默认没有 `标签` 页面和 `关于` 页面，需要在 source 目录下新建 tags 目录和 about 目录。推荐使用如下命令来新建，因为这样新建的目录可以被 hexo 所索引。\n\n```powershell\n> hexo new page tags\n> hexo new page about\n```\n\n接着，在 `tags` 目录下新建 `index.md`，并写入：\n\n```powershell\n---\nlayout: \"tags\"\ntitle: \"Tags\"\n---\n```\n\n在 `about` 目录下新建 `index.md`，并写入：\n\n```powershell\n---\nlayout: \"about\"\ntitle: \"About\"\ndate: 2022-7-27 07:54:00\n---\n```\n\n**favicon 配置**\n\n项目的 favicon 默认在 `<folder>/source/img` 下面，在 `<folder>/source/img` 下面添加 favicon.ico 即可。\n\n**头像配置**\n\n同 favicon 配置，在 `<folder>/source/img` 添加头像图片，然后在 `<folder>/_config.yml` 中配置如下内容：\n\n```powershell\nsidebar-avatar: img/<picture_file>\n```\n\n**底部自定义**\n\n直接在 `<folder>/_config.yml` 中配置相应的内容即可。\n\n```powershell\n# SNS settings\n# 一些社交平台地址，支持以下几种：\nweibo_username:     3286578617\nzhihu_username:     ai-er-lan-xue-da\ngithub_username:    AirCloud\ntwitter_username:   iconie_alloy\nfacebook_username:  xiaotao.nie.5\nlinkedin_username:  小涛-聂-80964aba\n```\n\n**字体配置**\n\n本节选用了一款优秀的中文衬线字体—思源宋体（`Noto Serif Simplified Chinese`）以及一款优秀的英文衬线字体—`EB Garamond`，以此来说明如何配置 Web 字体。\n\n![Fonts](Fonts.png)\n\n所谓的 Web 字体是指，当访问网站时，浏览器将自动从字体服务器下载选定的网络字体，接着网站文本将以选定的字体进行显示。常用的字体服务器有，[Google Fonts](https://fonts.google.com/) 和 [Typekit](https://fonts.adobe.com/)。\n\n以 Google Fonts 为例。主要配置流程如下：\n1. 选择字体（Google 的网站）\n    - 打开[思源宋体的网址](https://fonts.google.com/noto/specimen/Noto+Serif+SC)，下拉至 `Styles` 小节处，点击右侧的＋符号来选定不同粗细的字体；\n    - 打开 [EB Garamond 的网址](https://fonts.google.com/specimen/EB+Garamond?query=EB+Garamond#standard-styles)，以同样的方式选定字体。\n\n2. 获取 Google 字体代码\n    - 点击右上角 `View selected families`\n    - 复制 `link` 处的 HTML 代码，粘贴至 `<folder>/themes/hexo-theme-aircloud-master/layout/_partial/head.ejs`\n    ![Web Fonts.png](Web-Fonts.png)\n    - 复制 `CSS rules to specify families` 下的 CSS 代码，粘贴至 `<folder>/themes/hexo-theme-aircloud-master/source/css/aircloud.css`\n    ![WebFontsCSS.png](WebFontsCSS.png)\n\n3. 重新生成并部署静态网站\n    ```Powershell\n    > hexo generate\n    > hexo deploy\n    ```\n\n现在打开网站以后，便会以新的字体呈现内容！\n\n**更多配置**\n\n更多配置可以参考：\n\n- [https://github.com/aircloud/hexo-theme-aircloud](https://github.com/aircloud/hexo-theme-aircloud)\n- [https://github.com/aircloud/hexo-aircloud-blog/blob/master/_config.yml](https://github.com/aircloud/hexo-aircloud-blog/blob/master/_config.yml)\n\n## 3.3 生成新的静态文件，运行并部署\n\n至此，已经对主题进行了一些基本的配置。接着，生成新的静态文件，在本地服务器测试没问题后，部署到 GitHub Pages 上即可。\n\n```powershell\n> hexo clean\n> hexo generate\n> hexo server\n```\n\n```powershell\n> hexo deploy\n```\n\n等待 2-3 分钟后，打开网址`https://<your username>.github.io`，就可以看到网站已经部署成功了。\n\n# 总结\n\n这篇博客介绍了 hexo 静态博客框架、 GitHub Pages 静态网站托管平台以及如何搭建 Hexo 博客并部署到 GitHub Pages 的全流程，包括软件的安装与配置、初始化 Hexo 工程，Hexo 的基本操作、将 Hexo 文件推送到 GitHub 仓库以及配置 Hexo 主题。希望对你有所帮助。\n\n如果你想了解更多，可以查阅参考链接。\n\n# 参考\n\n- Hexo 博客搭建教程：[https://www.bilibili.com/read/cv12633102/](https://www.bilibili.com/read/cv12633102/)\n- 文档 | Hexo：[https://hexo.io/zh-cn/docs/](https://hexo.io/zh-cn/docs/)\n- Hexo 主题社区：[https://hexo.io/themes/](https://hexo.io/themes/)\n- AirCloud 主题地址：[https://github.com/aircloud/hexo-theme-aircloud](https://github.com/aircloud/hexo-theme-aircloud)\n- 什么是 npm：[https://chinese.freecodecamp.org/news/what-is-npm-a-node-package-manager-tutorial-for-beginners/](https://chinese.freecodecamp.org/news/what-is-npm-a-node-package-manager-tutorial-for-beginners/)\n- GitHub Pages： [https://pages.github.com/](https://pages.github.com/)\n- Google Fonts: https://fonts.google.com/noto/use#how-are-noto-fonts-organized\n- Google Fonts 已支持思源宋体！: https://io-oi.me/tech/noto-serif-sc-added-on-google-fonts/","tags":["博客"]}]